{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eba36d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "import os\n",
    "\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "import shutil\n",
    "\n",
    "CFG = SimpleNamespace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ebaaa5",
   "metadata": {},
   "source": [
    "# 01 - Extract frames from video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a6f6e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract n random frames from a video file\n",
    "\n",
    "def extract_random_frames(video_path, output_dir, n, size=(500, 500)):\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(f\"Total frames in video: {total_frames}\")\n",
    "\n",
    "    # Get n unique random frame indices\n",
    "    frame_indices = sorted(random.sample(range(total_frames), n))\n",
    "    \n",
    "    saved = 0\n",
    "    for idx in frame_indices:\n",
    "        video.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "        ret, frame = video.read()\n",
    "        if ret:\n",
    "            resized = cv2.resize(frame, size)\n",
    "            filename = os.path.join(output_dir, f\"frame_{idx}.jpg\")\n",
    "            cv2.imwrite(filename, resized)\n",
    "            saved += 1\n",
    "    video.release()\n",
    "    print(f\"Saved {saved} frames to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a170fd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames in video: 2731\n",
      "Saved 100 frames to frames\n"
     ]
    }
   ],
   "source": [
    "CFG.PATH_TO_VIDEO = 'videos/testvideo_1.mp4'\n",
    "CFG.PATH_TO_FRAMES = 'frames'\n",
    "\n",
    "extract_random_frames(\n",
    "    video_path=CFG.PATH_TO_VIDEO,\n",
    "    output_dir=CFG.PATH_TO_FRAMES,\n",
    "    n=100,\n",
    "    size=(640, 360),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1d9116",
   "metadata": {},
   "source": [
    "# 02 - Reduce video size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47357635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "# Reduce the size of the video file\n",
    "def reduce_video_size(video_path, output_path, size=(640, 360)):\n",
    "    # Open the video file\n",
    "    video = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    # Get the original video properties\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = video.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    \n",
    "    # Create VideoWriter object\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, size)\n",
    "\n",
    "    with tqdm.tqdm(total=frame_count, desc=\"Processing frames\") as pbar:\n",
    "        while True:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            resized_frame = cv2.resize(frame, size)\n",
    "            out.write(resized_frame)\n",
    "            pbar.update(1)\n",
    "\n",
    "    video.release()\n",
    "    out.release()\n",
    "    print(f\"Video saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe18702c",
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG.PATH_TO_VIDEO = 'videos/testvideo_1.mp4'\n",
    "CFG.RED_SIZE = (640, 360)\n",
    "CFG.PATH_TO_RED_VIDEO = Path(str(CFG.PATH_TO_VIDEO).replace('.mp4', f'_{CFG.RED_SIZE[0]}x{CFG.RED_SIZE[1]}.mp4'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda25ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|██████████| 2731/2731 [00:07<00:00, 342.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved to videos\\testvideo_1_640x360.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "reduce_video_size(\n",
    "    video_path=CFG.PATH_TO_VIDEO,\n",
    "    output_path=CFG.PATH_TO_RED_VIDEO,\n",
    "    size=CFG.REDUCED_VIDEO_SIZE,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da994a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d82d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176784ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3f9245",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc5fbd03",
   "metadata": {},
   "source": [
    "# 03 - Split dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfff844b",
   "metadata": {},
   "source": [
    "- Export annotated images in format 'YOLO with images'\n",
    "- Unzip file and move the content to .\\annotation_export\n",
    "- Run the code below\n",
    "    - The first cell to delete the existing dataset\n",
    "    - The second cell to split the images in train/val and move them to the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a4024e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the directory if it exists\n",
    "CFG.DATASET_DIR_PARENT = Path().cwd() / 'dataset'\n",
    "\n",
    "if CFG.DATASET_DIR_PARENT.exists() and CFG.DATASET_DIR_PARENT.is_dir():\n",
    "    shutil.rmtree(CFG.DATASET_DIR_PARENT)\n",
    "\n",
    "# Create the directories if they don't exist\n",
    "dataset_dir_list = [\n",
    "    CFG.DATASET_DIR_PARENT / 'images' / 'train',\n",
    "    CFG.DATASET_DIR_PARENT / 'images' / 'val',\n",
    "    CFG.DATASET_DIR_PARENT / 'labels' / 'train',\n",
    "    CFG.DATASET_DIR_PARENT / 'labels' / 'val',\n",
    "    ]\n",
    "\n",
    "for path in dataset_dir_list:\n",
    "    path.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "721b25b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 images found in c:\\Users\\thoma\\Documents\\GitHub\\follow_target\\annotation_export\\images\n",
      "20 images moved to validation set\n",
      "80 images moved to train set\n"
     ]
    }
   ],
   "source": [
    "path = Path().cwd() / 'annotation_export' / 'images'\n",
    "\n",
    "# Find all the images in the folder\n",
    "images = list(path.glob('*.jpg'))\n",
    "print(f'{len(images)} images found in {path}')\n",
    "\n",
    "# Set the number of images for training and validation\n",
    "n_val = int(len(images) * 0.2)\n",
    "\n",
    "# Take a random sample of 10 images for validation\n",
    "val_images = random.sample(images, n_val)\n",
    "\n",
    "for image in val_images:\n",
    "\n",
    "    # Get the image name without the extension\n",
    "    image_name = os.path.splitext(image.name)[0]\n",
    "\n",
    "    # Get the corresponding label path\n",
    "    label = path.parent / 'labels' / f'{image_name}.txt'\n",
    "\n",
    "    # Create the new path for the image and label\n",
    "    new_image_path = Path().cwd() / 'dataset' / 'images' / 'val' / f'{image_name}.jpg'\n",
    "    new_label_path  = Path().cwd() / 'dataset' / 'labels' / 'val' / f'{image_name}.txt'\n",
    "\n",
    "    # Move the files to the new path\n",
    "    shutil.move(image, new_image_path)\n",
    "    shutil.move(label, new_label_path)\n",
    "\n",
    "print(f'{len(val_images)} images moved to validation set')\n",
    "\n",
    "# Find all the images in the folder\n",
    "images = list(path.glob('*.jpg'))\n",
    "\n",
    "# Move the rest of the images to the training set\n",
    "for image in images:\n",
    "    # Get the image name without the extension\n",
    "    image_name = os.path.splitext(image.name)[0]\n",
    "\n",
    "    # Get the corresponding label path\n",
    "    label = path.parent / 'labels' / f'{image_name}.txt'\n",
    "\n",
    "    # Create the new path for the image and label\n",
    "    new_image_path = Path().cwd() / 'dataset' / 'images' / 'train' / f'{image_name}.jpg'\n",
    "    new_label_path  = Path().cwd() / 'dataset' / 'labels' / 'train' / f'{image_name}.txt'\n",
    "\n",
    "    # Move the files to the new path\n",
    "    shutil.move(image, new_image_path)\n",
    "    shutil.move(label, new_label_path)\n",
    "\n",
    "print(f'{len(images)} images moved to train set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ff7481",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
